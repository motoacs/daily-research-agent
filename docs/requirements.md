# daily-research-agent：プロジェクト説明（Codex引き継ぎ用）

1. 目的（What / Why）

本プロジェクトは、ローカル環境（PC / Ubuntu Server）上で動作する「定時リサーチ記事作成エージェント」のプロトタイプを作成する。
エージェントは外部情報源から自律的に情報を収集し、与えられた記事要件（形式・品質条件）を満たす 高品質なMarkdown記事を生成する。

狙いは、単発のニュース要約ではなく、今後「さまざまな業務置換エージェント」へ拡張可能な足場を作ること。初期フェーズではデプロイ（Hugo公開等）は行わず、ローカルにMarkdownファイルを生成するところまでにスコープを限定する。

2. スコープ（In Scope）

2.1 初期機能：定時リサーチ記事生成
- 指定プロンプト（記事テーマ、制約、品質条件）を入力として受け取り、記事をMarkdownで出力する。
- 情報収集は以下を組み合わせる：
- Perplexity MCP Server を用いたWebリサーチ（一次情報・複数ソース参照を前提）
- X（Twitter）ブックマークの取得（後述）
- 収集結果から「不足情報」「深掘り価値のある論点」を判断し、必要に応じて追加調査を自律的に実行
- 出力は ローカルファイル（Markdown）として保存する（ディレクトリ規約は任意。ただし日次運用を想定し、日付/テーマで整理しやすい形が望ましい）。

2.2 初期機能：Xブックマーク取得
- 事前に登録済みのX API資格情報を利用し、ユーザー自身のアカウントのブックマークを「新しい順」に 所定件数取得する。
- 取得対象は「ブックマークしたポスト」であり、現時点では“いいね”取得は必須ではない（後で拡張可能なら尚良い）。
- 取得したポストは記事生成の「種データ」として使える形でエージェントへ渡す（URL、本文、著者、作成時刻等が望ましい）。

3. 非スコープ（Out of Scope）
- Hugo等によるサイト生成・デプロイ（Git push、CI、ホスティング、Discord通知など）は初期フェーズでは実施しない。
- 100%の正確性保証は目標にしない（後述の品質要件に合致すれば良い）。
- UI（Web/GUI）は作らない。CLIで良い。

4. 技術方針（How：大枠）
- フレームワーク：LangChain deepagents を用いてプロトタイプを構築する。
- deepagentsの「todo/サブエージェント/ファイル中心のコンテキスト管理」を活用し、長い調査結果を破綻させず記事に落とすことを重視する。
- 外部接続：
- Perplexity MCP Server（MCP経由で検索・調査）
- X API（ブックマーク取得）
- 実行環境：
- ローカルPC/Ubuntu Serverで実行可能
- 依存管理はuvを使用
- 実装言語はPythonを想定（deepagentsがPython中心のため）。

5. 品質要件（ビジネス要件）

5.1 エージェンティックに動く（臨機応変さ）
- 「プロンプト条件を満たすために何が足りないか」を判断し、追加調査を自走できること。
- ただの要約ではなく、論点整理、比較、トレードオフ、根拠（出典）を伴う記事生成ができること。

5.2 正確性より“実用的に賢い”を優先
- 100%の正確性より、エージェントとしての探索・統合能力を重視する。
- ただし“それっぽい断定”を避け、根拠不足は不確実として表現するなど、誤情報を増幅しないガードは必要。

5.3 再現性・改善容易性
- 生成物（Markdown）だけでなく、可能なら「参照したソース」「調査メモ」「採用/非採用理由」などが後から追える形になっていることが望ましい。
- 日々の改善（プロンプト改善、ソース追加、調査ステップ調整）が短いサイクルで回せる構造であること。

6. 制約・注意点（運用/セキュリティ）
- X API資格情報や各種キーは、リポジトリに直書きしない（環境変数 or .env 等で管理）。
- deepagentsのファイル操作/シェル操作を使う場合、作業ディレクトリを限定し、意図しないファイル読み書きをしない設計が望ましい（プロトタイプでも事故防止）。
- X上のコンテンツ利用は規約・権利の配慮が必要。記事に引用する場合は、URL参照・短い引用・要約中心など、過剰転載にならない形を基本とする（実装段階では「引用の粒度を制御できる」余地があると良い）。

7. 成功条件（Acceptance）
- コマンド1つで、指定テーマのリサーチ記事Markdownをローカルに生成できる。
- Perplexity MCP Serverを使って複数ソースから情報を集め、記事に出典（URL等）を含められる。
- X APIからブックマークを新しい順にN件取得し、記事生成の入力として活用できる。
- 生成記事がプロンプト条件（体裁/粒度/観点/長さ等）を概ね満たし、読み物として破綻していない。

8. 将来拡張の前提（今は作らないが、潰さない）
- 将来的に、以下のような業務置換へ広げる可能性がある：
- Pythonでデータ分析→レポート生成
- AWS CLI/SDKでDB等からデータ取得→分析→報告
- 特定APIの手順テスト（回帰テスト）→結果まとめ
- よって、初期実装でも「情報源追加」「ツール追加」「記事テンプレ追加」がしやすい構成が望ましい。

---

開発担当への補足（意図）
- deepagentsは“成果物をファイルに落としながら進める”思想が強い。今回の「ローカルMarkdown生成」スコープに合致する。
- Xブックマーク取得は、記事作成の「自分の興味/重要視した話題」を反映させる目的。単なるソース追加ではなく、編集方針の入力として扱えると理想。
